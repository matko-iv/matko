<!DOCTYPE html>
<html lang="sr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tačnije Vremenske Prognoze za Budvu – Matija Ivanović</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
            font-size: 18px;
            line-height: 1.6;
            color: #24292e;
            background: #ffffff;
            max-width: 680px;
            margin: 0 auto;
            padding: 60px 20px;
        }

        h1 {
            font-size: 40px;
            font-weight: 600;
            margin-bottom: 12px;
            line-height: 1.25;
            color: #24292e;
        }

        h2 {
            font-size: 30px;
            font-weight: 600;
            margin-top: 50px;
            margin-bottom: 18px;
            line-height: 1.25;
            color: #24292e;
        }

        h3 {
            font-size: 22px;
            font-weight: 600;
            margin-top: 35px;
            margin-bottom: 14px;
            color: #24292e;
        }

        p {
            margin-bottom: 18px;
            color: #24292e;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .date {
            color: #586069;
            font-size: 16px;
            margin-bottom: 40px;
        }

        img {
            max-width: 100%;
            height: auto;
            margin: 30px 0;
            display: block;
            border-radius: 3px;
        }

        code {
            background: #f6f8fa;
            padding: 3px 6px;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }

        ul, ol {
            margin-left: 28px;
            margin-bottom: 18px;
        }

        li {
            margin-bottom: 6px;
        }

        table {
            width: 100%;
            margin: 28px 0;
            border-collapse: collapse;
            font-size: 16px;
        }

        th {
            text-align: left;
            padding: 10px;
            border-bottom: 2px solid #e1e4e8;
            font-weight: 600;
        }

        td {
            padding: 10px;
            border-bottom: 1px solid #e1e4e8;
        }

        tr:last-child td {
            border-bottom: none;
        }

        .note {
            background: #f6f8fa;
            border-left: 3px solid #586069;
            padding: 15px 20px;
            margin: 28px 0;
            font-size: 16px;
        }

        .site-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 60px;
            padding-bottom: 20px;
            border-bottom: 1px solid #e1e4e8;
            font-size: 15px;
        }

        .site-header a {
            color: #586069;
            text-decoration: none;
        }

        .site-header a:hover {
            color: #24292e;
        }

        .site-header .site-name {
            font-weight: 600;
            color: #24292e;
        }

        .site-header nav a {
            margin-left: 20px;
        }

        @media (max-width: 680px) {
            body {
                font-size: 16px;
                padding: 40px 16px;
            }

            h1 {
                font-size: 32px;
            }

            h2 {
                font-size: 26px;
            }

            h3 {
                font-size: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="site-header">
        <a href="/" class="site-name">Matija Ivanović</a>
        <nav>
            <a href="#">Blog</a>
            <a href="https://github.com/matko-iv" target="_blank">GitHub</a>
            <a href="mailto:ivanovicmatija2007@gmail.com">Kontakt</a>
        </nav>
    </div>

    <p class="date">Februar 2026</p>
    <h1>Tačnije Vremenske Prognoze za Budvu</h1>

    <p>Ideja je jednostavna: globalni meteorološki modeli su odlični, ali često prave sitne sistematske greške kada prognoziraju vrijeme za određenu lokaciju. Moj cilj je da te greške identifikujem i ispravim koristeći mašinsko učenje.</p>

    <p>Projekat sam započeo nakon što sam primijetio da prognoze često pothlađuju stvarnu temperaturu u Budvi. Znatiželjan sam da li je to konzistentan obrazac i da li mogu napraviti nešto po tom pitanju.</p>

    <h2>Problem</h2>

    <p>Globalni meteorološki modeli kao što su ECMWF, GFS ili ICON pokrivaju cijelu planetu i izvrsno rade posao na velikom nivou. Međutim, lokalna geografija, blizina mora, i specifičnosti Budve (kao što je BURA - jak sjeveroistočni vjetar) stvaraju uslove koje globalni modeli ne mogu savršeno uhvatiti.</p>

    <p>Uzeo sam 5 različitih globalnih modela (ECMWF IFS025, ICON Seamless, GFS Seamless, MeteoFrance i ARPEGE Europe) i uporedio njihove prognoze sa stvarnim mjerenjima sa meteo stanice u Budvi tokom posljednje 3 godine. To mi je dalo preko 24,000 satnih tačaka podataka po modelu.</p>

    <h2>Metodologija</h2>

    <h3>Mean Absolute Error (MAE)</h3>

    <p>Najvažnija metrika koju koristim je Mean Absolute Error (MAE) — srednja apsolutna greška. MAE mjeri prosječnu veličinu grešaka u skupu prognoza, bez obzira na njihov smjer. Za svako satno mjerenje, uzimam razliku između prognozirane i stvarne vrijednosti, uzmem apsolutnu vrijednost te razlike, i na kraju prosjek svih tih apsolutnih razlika daje MAE:</p>

    <img src="https://latex.codecogs.com/svg.image?MAE=\frac{1}{n}\sum_{i=1}^{n}|y_{pred}-y_{true}|" alt="MAE formula">

    <p>Na primjer, ako model prognozira temperature od 20°C, 22°C i 18°C, a stvarne temperature su 19°C, 24°C i 17°C, onda su apsolutne greške 1°C, 2°C i 1°C, pa je MAE = (1+2+1)/3 = 1.33°C.</p>

    <p>MAE je intuitivan jer se izražava u istim jedinicama kao i originalni podaci (stepeni Celzijusa za temperaturu, m/s za vjetar). Ako je MAE za temperaturu 1.5°C, to bukvalno znači da u prosjeku prognoza promašuje za 1.5 stepeni. Niska vrijednost MAE ukazuje na preciznije prognoze. Još jedna prednost MAE-a je da tretira sve greške linearno — greška od 5°C je tačno pet puta „gora" od greške od 1°C, što ga čini robusnim na pojedinačne ekstremne promašaje.</p>

    <h3>Mean Squared Error (MSE) i Root Mean Squared Error (RMSE)</h3>

    <p>Druga veoma korisna metrika je Mean Squared Error (MSE) — srednja kvadratna greška. Za razliku od MAE koji uzima apsolutne vrijednosti, MSE kvadrira svaku pojedinačnu grešku prije prosjeka:</p>

    <img src="https://latex.codecogs.com/svg.image?MSE=\frac{1}{n}\sum_{i=1}^{n}(y_{pred}-y_{true})^2" alt="MSE formula">

    <p>Kvadriranje ima važnu posljedicu: veće greške se kažnjavaju neproporcijalno više. Greška od 5°C doprinosi sa 25 jedinica, dok greška od 1°C doprinosi samo sa 1 jedinicom — dakle pet puta veća greška u apsolutnom smislu daje 25 puta veći doprinos u MSE. To znači da je MSE posebno osjetljiv na „velike promašaje" — ako model povremeno napravi veliku grešku, MSE će to snažno reflektovati, čak i ako je većina prognoza tačna.</p>

    <p>Pošto MSE daje rezultat u kvadriranim jedinicama (°C²), često se koristi korijen iz MSE — Root Mean Squared Error (RMSE) — koji vraća metriku u originalne jedinice:</p>

    <img src="https://latex.codecogs.com/svg.image?RMSE=\sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_{pred}-y_{true})^2}" alt="RMSE formula">

    <p>RMSE je uvijek veći ili jednak MAE. Razlika između RMSE i MAE govori o varijabilnosti grešaka: ako su RMSE i MAE slični, to znači da su greške uglavnom konstantne veličine. Ako je RMSE značajno veći od MAE, to ukazuje da postoje i neke velike greške pored manjih.</p>

    <img src="images/07_mae_vs_rmse.png" alt="Poređenje MAE i RMSE za sve modele">

    <h3>Bias (sistematska greška)</h3>

    <p>Takođe sam računao bias (sistematsku grešku):</p>

    <img src="https://latex.codecogs.com/svg.image?Bias=\frac{1}{n}\sum_{i=1}^{n}(y_{pred}-y_{true})" alt="Bias formula">

    <p>Pozitivan bias znači da model pregrijava, negativan da pothlađuje. Za razliku od MAE i MSE, bias ne koristi apsolutne vrijednosti niti kvadrate — pozitivne i negativne greške se međusobno poništavaju. To čini bias korisnim za otkrivanje sistematskih tendencija: model sa bias-om od -0.9°C konzistentno predviđa nižu temperaturu od stvarne.</p>

    <h2>Rezultati</h2>

    <p>Analiza je potvrdila moje sumnje. Evo šta sam otkrio:</p>

    <table>
        <thead>
            <tr>
                <th>Model</th>
                <th>MAE Temp (°C)</th>
                <th>Bias (°C)</th>
                <th>MAE Vjetar (m/s)</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>ARPEGE Europe</td>
                <td>1.39</td>
                <td>-0.51</td>
                <td>1.56</td>
            </tr>
            <tr>
                <td>MeteoFrance</td>
                <td>1.39</td>
                <td>-0.51</td>
                <td>1.56</td>
            </tr>
            <tr>
                <td>GFS Seamless</td>
                <td>1.74</td>
                <td>-0.85</td>
                <td>1.48</td>
            </tr>
            <tr>
                <td>ECMWF IFS025</td>
                <td>1.80</td>
                <td>-0.92</td>
                <td>0.71</td>
            </tr>
            <tr>
                <td>ICON Seamless</td>
                <td>1.97</td>
                <td>+0.71</td>
                <td>1.23</td>
            </tr>
        </tbody>
    </table>

    <img src="images/01_model_performance_overview.png" alt="Pregled performansi modela">

    <p>Nekoliko stvari je očito. Prvo, većina modela ima negativan bias za temperaturu - što znači da sistematski pothlađuju Budvu za pola stepena ili više. Samo ICON ima pozitivan bias (pregrijava). Drugo, greške nisu uniforme tokom cijele godine. Zimi su veće nego ljeti.</p>

    <img src="images/02_systematic_bias.png" alt="Sistematski bias temperature i vjetra">

    <img src="images/06_model_comparison_matrix.png" alt="Matrica poređenja modela">

    <p>Posebno me je zanimala BURA - jak sjeveroistočni vjetar koji puše sa planina prema moru. Definisao sam je kao vjetar brzine preko 8 m/s iz smjera između 315° i 45°. Tokom BURE, modeli imaju značajno veće greške nego inače.</p>

    <img src="images/03_seasonal_analysis.png" alt="Sezonska analiza grešaka">

    <h2>Sezonski obrasci</h2>

    <p>Greške se značajno razlikuju po sezonama. Ljeti su najveće, što je vjerovatno zbog intenzivnijih konvektivnih procesa i lokalne cirkulacije zbog mora.</p>

    <img src="images/08_bias_heatmap.png" alt="Heatmapa sezonskog biasa">

    <img src="images/04_diurnal_cycle.png" alt="Dnevni ciklus grešaka">

    <img src="images/09_weather_condition_comparison.png" alt="Poređenje po vremenskim uslovima">

    <h2>Dodatna analiza</h2>

    <p>Pored osnovnih metrika, analizirao sam i sposobnost modela da predviđaju oblačnost i padavine — dva parametra koja su tradicionalno teška za prognozu na lokalnom nivou.</p>

    <img src="images/12_cloudiness_skill.png" alt="Vještina predviđanja oblačnosti">

    <img src="images/10_precipitation_intensity.png" alt="Intenzitet padavina">

    <p>Radar grafik ispod prikazuje performanse svakog modela na svim analiziranim varijablama — temperatura, brzina vjetra, padavine, oblačnost — dajući kompletnu sliku prednosti i slabosti svakog modela.</p>

    <img src="images/11_radar_all_variables.png" alt="Radar grafik svih varijabli">

    <h2>Kako to popraviti</h2>

    <p>Ideja je da treniram model mašinskog učenja (konkretno XGBoost) koji će naučiti iz grešaka koje globalni modeli prave. Model uzima sirove prognoze kao input i daje korigovanu prognozu kao output.</p>

    <p>Ključno je kreirati dobre feature-e. Pored sirovih prognoza, dodajem:</p>

    <ul>
        <li>Ensemble statistike — prosjek, standardna devijacija, raspon i medijana prognoza sva 4 modela</li>
        <li>Devijacije — koliko svaki model odstupa od ensemble prosjeka</li>
        <li>Ciklične varijable — sat u danu i dan u godini kao sin/cos funkcije</li>
        <li>BURA detekcija — flag iz svakog modela + agreement (koliko modela detektuje buru)</li>
        <li>Sezonski faktori — zima/proljeće/ljeto/jesen</li>
        <li>Cross-parameter interakcije — razlika temp/dew point, odnos vjetra i pritiska</li>
    </ul>

    <p>Loss funkcija koju minimiziram je također Mean Absolute Error:</p>

    <img src="https://latex.codecogs.com/svg.image?L=\frac{1}{n}\sum_{i=1}^{n}|f(x_i)-y_i|" alt="Loss function">

    <p>Cilj je spustiti MAE ispod 1.0°C. To bi bilo poboljšanje od oko 30-40% u odnosu na najbolji globalni model.</p>

    <h2>Kako XGBoost funkcioniše</h2>

    <p>XGBoost (eXtreme Gradient Boosting) je algoritam mašinskog učenja baziran na ansamblu stabala odlučivanja. Za razliku od klasičnog random foresta koji trenira stabla nezavisno, XGBoost ih gradi <em>sekvencijalno</em> — svako novo stablo pokušava ispraviti greške prethodnih.</p>

    <h3>Osnovna ideja: aditivno treniranje</h3>

    <p>Model se gradi iterativno. Konačna predikcija je suma predikcija svih stabala:</p>

    <img src="https://latex.codecogs.com/svg.image?\hat{y}_i=\sum_{k=1}^{K}f_k(x_i),\quad%20f_k\in\mathcal{F}" alt="XGBoost prediction formula" style="margin: 20px auto; display: block;">

    <p>gdje je <em>K</em> broj stabala, <em>f<sub>k</sub></em> je predikcija k-tog stabla, a <em>F</em> je prostor svih mogućih stabala odlučivanja (CART stabla).</p>

    <p>U svakoj iteraciji <em>t</em>, dodajemo novo stablo <em>f<sub>t</sub></em> koje minimizira grešku. Predikcija nakon <em>t</em> koraka:</p>

    <img src="https://latex.codecogs.com/svg.image?\hat{y}_i^{(t)}=\hat{y}_i^{(t-1)}+\eta\cdot%20f_t(x_i)" alt="Additive training" style="margin: 20px auto; display: block;">

    <p>gdje je η (eta) <strong>learning rate</strong> — hiperparametar koji kontroliše koliko jako svako novo stablo utiče na konačni rezultat. Manji η znači sporije učenje ali bolju generalizaciju.</p>

    <h3>Objektivna funkcija</h3>

    <p>XGBoost minimizira regularizovanu objektivnu funkciju:</p>

    <img src="https://latex.codecogs.com/svg.image?\mathcal{L}=\sum_{i=1}^{n}\ell(\hat{y}_i,y_i)+\sum_{k=1}^{K}\Omega(f_k)" alt="Objective function" style="margin: 20px auto; display: block;">

    <p>Prvi dio je <strong>loss funkcija</strong> (u našem slučaju MAE), a drugi dio je <strong>regularizacija</strong> koja penalizuje kompleksnost stabala:</p>

    <img src="https://latex.codecogs.com/svg.image?\Omega(f)=\gamma%20T+\frac{1}{2}\lambda\sum_{j=1}^{T}w_j^2+\alpha\sum_{j=1}^{T}|w_j|" alt="Regularization term" style="margin: 20px auto; display: block;">

    <p>gdje je <em>T</em> broj listova u stablu, <em>w<sub>j</sub></em> su težine (vrijednosti) u listovima, γ je penalizacija za broj listova, λ je L2 regularizacija, a α je L1 regularizacija. Ova regularizacija sprečava overfitting i razlikuje XGBoost od klasičnog gradient boostinga.</p>

    <h3>Aproksimacija drugog reda</h3>

    <p>Ključna inovacija XGBoost-a je korištenje Taylor ekspanzije drugog reda za loss funkciju. U koraku <em>t</em>:</p>

    <img src="https://latex.codecogs.com/svg.image?\mathcal{L}^{(t)}\approx\sum_{i=1}^{n}\left[g_i%20f_t(x_i)+\frac{1}{2}h_i%20f_t^2(x_i)\right]+\Omega(f_t)" alt="Second order approximation" style="margin: 20px auto; display: block;">

    <p>gdje su:</p>

    <img src="https://latex.codecogs.com/svg.image?g_i=\frac{\partial\ell(\hat{y}_i^{(t-1)},y_i)}{\partial\hat{y}_i^{(t-1)}},\quad%20h_i=\frac{\partial^2\ell(\hat{y}_i^{(t-1)},y_i)}{\partial(\hat{y}_i^{(t-1)})^2}" alt="Gradients" style="margin: 20px auto; display: block;">

    <p><em>g<sub>i</sub></em> je prvi izvod (gradijent), a <em>h<sub>i</sub></em> drugi izvod (hesijan) loss funkcije. Ovo je ono što daje "Gradient" u imenu — svako novo stablo se uklapa na gradijente grešaka prethodnih stabala.</p>

    <h3>Optimalna težina listova</h3>

    <p>Za dato stablo sa strukturom <em>q</em>, optimalna težina u svakom listu <em>j</em> je:</p>

    <img src="https://latex.codecogs.com/svg.image?w_j^*=-\frac{\sum_{i\in%20I_j}g_i}{\sum_{i\in%20I_j}h_i+\lambda}" alt="Optimal leaf weight" style="margin: 20px auto; display: block;">

    <p>a odgovarajuća optimalna vrijednost loss funkcije:</p>

    <img src="https://latex.codecogs.com/svg.image?\mathcal{L}^*=-\frac{1}{2}\sum_{j=1}^{T}\frac{(\sum_{i\in%20I_j}g_i)^2}{\sum_{i\in%20I_j}h_i+\lambda}+\gamma%20T" alt="Optimal loss" style="margin: 20px auto; display: block;">

    <p>gdje je <em>I<sub>j</sub></em> skup podataka koji pripada listu <em>j</em>.</p>

    <h3>Kako se stablo dijeli (Split Gain)</h3>

    <p>Prilikom gradnje svakog stabla, XGBoost bira optimalni split evaluirajući <strong>gain</strong> za svako moguće dijeljenje:</p>

    <img src="https://latex.codecogs.com/svg.image?Gain=\frac{1}{2}\left[\frac{(\sum_{i\in%20I_L}g_i)^2}{\sum_{i\in%20I_L}h_i+\lambda}+\frac{(\sum_{i\in%20I_R}g_i)^2}{\sum_{i\in%20I_R}h_i+\lambda}-\frac{(\sum_{i\in%20I}g_i)^2}{\sum_{i\in%20I}h_i+\lambda}\right]-\gamma" alt="Split gain formula" style="margin: 20px auto; display: block;">

    <p>Tri člana su: score lijevog djeteta + score desnog djeteta − score bez dijeljenja. Oduzimamo γ kao penalizaciju za dodavanje novog lista. Split se pravi samo ako je gain pozitivan.</p>

    <h3>Naša konfiguracija</h3>

    <p>Za korekciju vremenskih prognoza koristim sljedeće hiperparametre:</p>

    <table>
        <tr><th>Parametar</th><th>Vrijednost</th><th>Značenje</th></tr>
        <tr><td><code>n_estimators</code></td><td>800</td><td>Maksimalan broj stabala (sa early stopping)</td></tr>
        <tr><td><code>max_depth</code></td><td>6</td><td>Maksimalna dubina svakog stabla</td></tr>
        <tr><td><code>learning_rate</code> (η)</td><td>0.05</td><td>Koliko jako svako novo stablo utiče</td></tr>
        <tr><td><code>subsample</code></td><td>0.8</td><td>Procenat podataka korišten za svako stablo</td></tr>
        <tr><td><code>colsample_bytree</code></td><td>0.7</td><td>Procenat feature-a korišten za svako stablo</td></tr>
        <tr><td><code>reg_alpha</code> (α)</td><td>0.1</td><td>L1 regularizacija (LASSO)</td></tr>
        <tr><td><code>reg_lambda</code> (λ)</td><td>1.0</td><td>L2 regularizacija (Ridge)</td></tr>
        <tr><td><code>min_child_weight</code></td><td>5</td><td>Minimalni zbroj hesijana u listu</td></tr>
    </table>

    <p>Treniram <strong>poseban model za svaki parametar</strong> (temperatura, pritisak, vlažnost, vjetar, tačka rose, udari vjetra), koristeći prognoze sva 4 modela kao input. Na validacionom setu (juli 2025 — februar 2026), rezultati su:</p>

    <table>
        <tr><th>Parametar</th><th>XGBoost MAE</th><th>Najbolji model MAE</th><th>Poboljšanje</th></tr>
        <tr><td>Temperatura</td><td>0.98°C</td><td>1.32°C (MétéoFrance)</td><td>+26%</td></tr>
        <tr><td>Tačka rose</td><td>1.37°C</td><td>2.34°C (MétéoFrance)</td><td>+42%</td></tr>
        <tr><td>Vlažnost</td><td>6.87%</td><td>10.82% (GFS)</td><td>+37%</td></tr>
        <tr><td>Brzina vjetra</td><td>0.45 m/s</td><td>1.16 m/s (ICON)</td><td>+62%</td></tr>
        <tr><td>Udari vjetra</td><td>0.59 m/s</td><td>1.75 m/s (GFS)</td><td>+66%</td></tr>
        <tr><td>Pritisak</td><td>0.32 hPa</td><td>0.92 hPa (GFS)</td><td>+65%</td></tr>
    </table>

    <div class="note">
        <strong>Ključna razlika od prethodnog modela:</strong> Ovaj model NE koristi lag feature-e opservacija (temperatura prije 1h, 6h...) za buduće prognoze — jer u realnom vremenu nemamo buduća mjerenja. Umjesto toga, oslanja se na ensemble statistike (prosjek, standardna devijacija, raspon između modela), ciklične vremenske varijable, i cross-parameter interakcije (npr. razlika temperature i tačke rose za detekciju magle).
    </div>

    <h2>Ukupno rangiranje</h2>

    <p>Na osnovu svih analiziranih parametara, evo ukupnog rangiranja modela za Budvu:</p>

    <img src="images/13_overall_ranking.png" alt="Ukupno rangiranje modela">

    <h2>Tehnički detalji</h2>

    <p>Cijeli projekat je napisan u Pythonu. Koristim <code>pandas</code> i <code>numpy</code> za obradu podataka, <code>matplotlib</code> i <code>seaborn</code> za vizualizacije, i <code>xgboost</code> za mašinsko učenje.</p>

    <p>Podatke preuzimam sa Open-Meteo API-ja, koji besplatno daje pristup istorijskim prognozama globalnih modela. Imam implementiran retry mehanizam jer postoje rate limiti.</p>

    <div class="note">
        <strong>Napomena:</strong> Kod projekta je potpuno open source i dostupan na GitHubu. Uključuje kompletan pipeline za preuzimanje podataka, analizu, vizualizaciju i pripremu za ML model.
    </div>

    <h2>Zašto sam zainteresovan za ovo</h2>

    <p>Živim u Budvi, i kao većina ljudi ovdje, koristim vremensku prognozu svakodnevno. Turizam je ogroman dio ekonomije, i tačna prognoza direktno utiče na odluke turista, lokalnih biznisa, i pomorskog saobraćaja.</p>

    <p>Ali isto tako, ovo je fascinantan problem iz perspektive data science-a. Globalni modeli su nevjerovatno sofisticirani - simuliraju cijelu atmosferu koristeći fizičke jednačine. Ali oni ne mogu biti perfektni za svaku pojedinačnu lokaciju. Tu dolazi mašinsko učenje - može naučiti lokalne obrasce bez potrebe da eksplicitno modelira fiziku.</p>

    <h2>Šta dalje</h2>

    <p>Production pipeline je <strong>završen</strong>. Sistem sada automatski:</p>

    <ol>
        <li>Preuzima live prognoze sa Open-Meteo API za sva 4 modela (ARPÈGE, GFS, ICON, Météo-France)</li>
        <li>Primjenjuje trenirane XGBoost modele na svaki parametar (temperatura, vlažnost, vjetar, pritisak, tačka rose)</li>
        <li>Generiše korigovanu +48h prognozu za Budvu u CSV i JSON formatu</li>
    </ol>

    <p>Padavine i oblačnost se prikazuju kao prosjek svih modela (ensemble mean), jer za te parametre nemamo pouzdane satne opservacije za trening. Ostali parametri prolaze kroz XGBoost korekciju sa mjerljivim poboljšanjem od 26-66%.</p>

    <p>Sljedeći korak je automatizacija — cron job koji svakih 6 sati generiše novu prognozu i objavljuje je na web interfejsu.</p>

    <p>Ako imate pitanja ili prijedloge, slobodno mi pišite na <a href="mailto:ivanovicmatija2007@gmail.com">ivanovicmatija2007@gmail.com</a>.</p>
</body>
</html>
